{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e0121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import Statevector\n",
    "from qiskit.circuit.library import ZFeatureMap, RealAmplitudes\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d7883",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261f8728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.2\n"
     ]
    }
   ],
   "source": [
    "print(medmnist.__version__)\n",
    "# note there is also mednist+!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677fed11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/ramonwinkler/.medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /Users/ramonwinkler/.medmnist/breastmnist.npz\n"
     ]
    }
   ],
   "source": [
    "from medmnist import BreastMNIST\n",
    "\n",
    "train_dataset = BreastMNIST(split='train', download=True)\n",
    "test_dataset  = BreastMNIST(split='test', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1cd5aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python_class': 'BreastMNIST',\n",
       " 'description': 'The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.',\n",
       " 'url': 'https://zenodo.org/records/10519652/files/breastmnist.npz?download=1',\n",
       " 'MD5': '750601b1f35ba3300ea97c75c52ff8f6',\n",
       " 'url_64': 'https://zenodo.org/records/10519652/files/breastmnist_64.npz?download=1',\n",
       " 'MD5_64': '742edef2a1fd1524b2efff4bd7ba9364',\n",
       " 'url_128': 'https://zenodo.org/records/10519652/files/breastmnist_128.npz?download=1',\n",
       " 'MD5_128': '363e4b3f8d712e9b5de15470a2aaadf1',\n",
       " 'url_224': 'https://zenodo.org/records/10519652/files/breastmnist_224.npz?download=1',\n",
       " 'MD5_224': 'b56378a6eefa9fed602bb16d192d4c8b',\n",
       " 'task': 'binary-class',\n",
       " 'label': {'0': 'malignant', '1': 'normal, benign'},\n",
       " 'n_channels': 1,\n",
       " 'n_samples': {'train': 546, 'val': 78, 'test': 156},\n",
       " 'license': 'CC BY 4.0'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e684dc2",
   "metadata": {},
   "source": [
    "Note: normal + benign are combined into one class: benign!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b53051f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce4998d",
   "metadata": {},
   "source": [
    "## Convert medmnist datset object into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d19eb074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save images and labels in a list\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for img, label in train_dataset:\n",
    "    images.append(np.array(img))\n",
    "    labels.append(int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "135ee81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df of the extracted data\n",
    "train_df = pd.DataFrame({\n",
    "    \"image\": images,\n",
    "    \"label\": labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "316b15e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "4f8de819-b364-4c5d-b694-58b7180f0526",
       "rows": [
        [
         "0",
         "[[139 139 138 139 142 149 156 159 164 167 168 163 166 169 164 166 162 158\n  164 156 156 165 161 154 156 165 162 165]\n [ 84  92  94  84  84  86  94 109 129 135 131 130 136 125 111 119 117 121\n  131 117 132 133 133 139 140 124 116 112]\n [ 84  82  87 101 101  96  90  95 106  97  86  97 116 107  91  86  77  91\n  128 129 129 130 136 136 128 124 127 126]\n [ 83  77  95 120 107  76  93  96 106 114 111 109  97  83  72  71  65  74\n   99 110 122 133 111 110 122 134 143 149]\n [ 76  73  89  94  89  79  73  74  83 109 110 119 110 103  83  75  71  77\n   88  97 117 122 120 119 134 132 131 128]\n [ 80  77  77  62  55  67  71  66  79  93 103 101 104 113 108  95  84  81\n  102 107 109 124 138 134 125 113 129 137]\n [ 90  91  84  67  50  59  84  87  97 108 138 134 132 142 146 150 125 109\n  122 129 128 104 108 111 123 126 129 126]\n [ 91  99 118 103  78  72 105 134 141 124 131 138 123 102  96  99  91  88\n  105 110  94  86 107 121 136 152 160 161]\n [108 116 149 139 113 100 112 124 120 115 119 124 122 111  97  87  83  93\n  103 118 120 119 131 129 115 121 123 130]\n [107 117 123 109 103 117 126 139 146 153 170 182 179 167 135 120 118 125\n  134 143 139 125 135 136 134 135 133 136]\n [153 148 133 139 135 137 144 143 140 134 144 162 169 160 139 136 137 149\n  164 174 170 150 148 151 141 134 142 154]\n [116 145 150 138 111  99 108 115 115 126 135 136 135 121 113 109 120 129\n  162 185 187 173 177 183 176 167 175 182]\n [108 130 136 121 116 119 120 126 145 164 177 161 136 130 135 152 152 148\n  157 159 158 148 150 158 155 150 157 158]\n [111 115 110 127 156 161 144 123 108 140 171 179 189 177 165 163 156 156\n  156 139 120 111 113 122 121 117 129 143]\n [123 134 139 145 144 118 102  91 102 139 198 202 180 169 167 155 147 143\n  134 126 112  90  89  94 101 115 144 157]\n [113 101 103 109 111 120 122 106 111 143 187 172 163 148 143 155 156 146\n  130 109  89  81  97  98 109 136 142 146]\n [ 81  95 109 112 118 145 146 113  95 106 133 139 133 128 133 142 132 113\n   97  76  74  80  94 114 137 157 173 164]\n [ 52  68  85 101 104 115 119 105  75  69  90  96 106 110 106 100  93  89\n   76  73  79  87 106 122 134 141 130 134]\n [ 75  82  92  96 102 107  95  83  71  66  76  73  73  78  76  72  70  80\n   78  78  87 100 111 123 133 139 139 134]\n [ 76  89  97  94  84  90  94  81  63  56  60  64  76  87  95 101  98 101\n  101  87  77  75  79  78  74  84  84  83]\n [ 60  67  81  77  68  73  80  74  63  57  63  87 110 114 103  98  93  88\n   80  64  52  49  48  50  49  51  55  63]\n [ 56  57  73  75  73  61  59  60  61  65  65  74  82  87  74  67  69  61\n   53  47  42  38  47  50  46  54  64  59]\n [ 56  68  67  54  49  52  59  61  57  57  55  60  68  71  65  59  55  55\n   47  41  36  36  47  47  44  47  53  50]\n [ 38  53  61  53  47  56  67  66  62  59  63  80  93  93  91  83  68  60\n   45  40  41  39  40  39  40  40  37  36]\n [ 45  51  54  58  71  88 106 108  98  90  77  81  85  87  91  84  73  71\n   54  39  35  37  43  47  49  40  35  31]\n [ 63  70  83  98 102  98  95  90  75  63  56  51  51  53  52  52  54  59\n   58  53  45  42  53  50  40  36  34  32]\n [ 59  70  73  83  84  75  66  64  52  46  41  40  39  35  35  33  31  33\n   35  39  40  39  40  46  52  50  40  34]\n [ 62  65  61  62  64  55  47  46  38  33  30  32  30  27  25  25  22  21\n   21  23  31  44  48  40  44  51  42  40]]",
         "1"
        ],
        [
         "1",
         "[[ 82  85  83  78  76  76  79  79  76  80  86  94  86  85  79  77  81  82\n   89  86  87  87  87  78  74  76  83  86]\n [ 80  82  68  72  82  91  86  77  71  66  65  64  57  59  61  57  63  72\n   77  83  90  92  80  63  62  59  61  64]\n [ 56  59  60  67  69  67  62  60  59  59  57  58  62  64  58  46  54  67\n   65  64  71  68  62  58  56  59  58  60]\n [ 69  64  59  63  69  71  79  89  85  77  76  78  65  57  49  35  39  66\n   72  75  72  72  70  69  69  75  71  61]\n [ 75  73  71  73  78  90 114 131 106  94 110 130 120  95  74  40  25  49\n   69  77  83  96 102 101  99 112 101  68]\n [106 103  95  93  69  43  41  87  94  72 113 141 135 120  98  74  57  69\n   77  80  74  67  79  73  81  89  68  40]\n [118 121  85  38   9   6   7  29  55  60  53  59  66  84  84  87  96 125\n  128 114  87  70  67  62  55  67  64  36]\n [ 97  90  72  33  12  18  25  23  29  14  10  17  17  22  34  62  77 116\n  145 153 146 115 105  94  83  88  77  52]\n [101  95  79  91  77  49  17   5   5   3   7  10   8   5  13  50  72 101\n  132 142 149 159 152 136 134 141 122  98]\n [ 98 100  91  90 105  73  14   2   3   4   6  10  10  24  50  60  70 101\n  127 138 131 129 129 119 122 139 121  93]\n [ 86  92  87  94 100  95  64  37  42  56  57  54  69  97 107  74  64  93\n  111 110 107 109 114 107  99 106  97  79]\n [ 76  76  67  78  88  93 110 105 119 133 144 137 132 127 107  72  55  65\n   77  70  73  82  80  77  78 100  84  72]\n [ 47  51  57  62  67  76  90 102 109 106 110 120 118 115  97  68  58  67\n   67  62  61  69  81  80  68  74  72  65]\n [ 37  35  42  55  65  67  74  84  88  96 105 116 114  99  75  58  54  56\n   59  62  67  74  78  78  78  69  66  59]\n [ 33  27  30  37  46  57  74  84  81  89  94 106 118 110  85  64  50  44\n   48  67  71  66  70  73  79  73  66  58]\n [ 34  25  24  25  31  39  54  64  70  71  79  93  98  98  80  71  65  60\n   63  73  64  50  49  49  64  67  55  45]\n [ 35  25  21  25  25  28  37  49  57  57  66  79  79  63  54  57  54  52\n   64  63  62  62  66  70  62  52  51  50]\n [ 47  36  24  24  26  26  28  35  47  52  58  70  74  67  60  55  48  48\n   53  46  48  56  67  69  59  48  49  55]\n [ 45  40  34  28  29  32  34  35  43  52  60  63  65  68  71  68  60  45\n   35  34  33  42  51  58  57  46  45  46]\n [ 44  36  41  45  51  57  50  40  43  53  62  64  64  58  51  48  48  43\n   35  27  30  33  43  38  30  29  33  38]\n [ 37  35  46  54  57  55  44  37  37  42  51  60  62  56  54  50  48  46\n   34  24  26  38  55  46  37  33  33  38]\n [ 38  48  56  49  40  41  39  33  32  36  43  51  55  56  63  64  61  59\n   64  55  43  38  38  42  45  38  32  30]\n [ 36  43  47  31  24  23  23  28  31  34  37  41  49  55  59  63  63  56\n   63  66  62  64  63  63  52  41  36  34]\n [ 38  47  43  26  19  18  20  24  28  35  38  41  51  62  66  64  52  42\n   44  52  45  38  36  34  36  35  32  28]\n [ 37  38  32  19  15  15  17  19  24  30  35  41  44  48  47  42  38  36\n   35  37  37  33  30  22  21  20  21  22]\n [ 24  23  19  14  13  13  14  16  19  24  28  33  34  33  35  38  37  34\n   33  44  52  45  32  25  19  18  18  17]\n [ 23  21  16  13  11  11  12  13  15  18  20  24  26  27  28  27  26  25\n   25  25  32  41  41  32  25  24  23  19]\n [ 22  24  18  14  12  11  11  12  13  15  16  17  19  22  22  22  22  27\n   25  22  21  24  28  33  27  26  22  19]]",
         "1"
        ],
        [
         "2",
         "[[157 155 151 145 149 146 141 134 141 143 145 143 138 142 149 148 145 140\n  141 136 134 131 129 135 133 130 128 131]\n [160 162 156 160 166 164 160 156 160 153 144 152 158 164 158 147 140 141\n  145 146 145 147 142 142 141 126 126 135]\n [129 119 122 130 121 106  93  94 110 119 118 126 125 121 129 135 120 107\n  106 101  94  91  97 112 126 114 110 110]\n [105 108 109 113 104 107  95  94 101 108 108 107 107 112 120 122 123 136\n  118 120 115 118 119 101 101 101  98  88]\n [122 122 122 116 118 125 110 108 116 122 134 138 134 132 138 139 128 107\n   95 101  99 114 111 121 137 131  92  66]\n [134 133 127 111 119 155 179 170 160 151 149 145 142 133 137 111  91  76\n   73  78  86 121 111 123 133 112  82  62]\n [129 132 124 107 108 121 140 140 145 141 150 170 176 161 117  97  88  70\n   75  96  85  95  96  84  78  88  88  66]\n [128 130 119 111 109 111 122 118 137 158 191 200 207 181 128 116 111 106\n  121 143  92  88  96  96 110 120 102  74]\n [131 124 118 114 115 107 111 148 160 166 179 174 171 131 105 110 122 108\n   81  82  78  86 106 107 116 143 126  92]\n [133 132 149 154 133 104 100 145 175 167 147 128 117  91  75  79  78  71\n   80  76  87 106 108  82  64  81  90  77]\n [155 140 140 133 126 129 113 116 127 118 113 117 120  95  87  94  72  66\n   79  76  89  85  69  56  52  68  83  78]\n [130 113 104 104  99  98  92  91 113 120 121 120 113 104 118  98  71  65\n   65  62  55  66  65  59  56  65  81  87]\n [132 126 121 106  99  88  81  94 108 112 107 110 118 112  94  77  69  65\n   63  64  53  64  68  71  80  92 110 133]\n [113 125 122 108  97  79  79  91  99 106 115 121 114  88  71  68  71  68\n   64  50  43  49  60  70  72  75 103 118]\n [ 99  94 102 106  81  65  82  98 114 129 145 136 100  86  73  68  86  67\n   53  42  38  46  57  55  60  74 102 100]\n [104 106 105  86  65  52  77 102 120 113 105 100  91  85  73  85 105  52\n   47  43  54  65  56  54  61  81  84  72]\n [114 106  82  70  58  54  88 117 107  93  95  93  90  94 101 123  95  43\n   52  52  60  56  55  57  63  67  70  86]\n [ 96  80  65  57  54  67  89 116 112 106 104  98 116 122 114 104  74  46\n   63  76  57  32  37  51  60  65  76  98]\n [ 90  90  85  61  56  81 116 122 115 110 100  76  73  83  73  69  62  66\n   82  61  44  56  80  97 100  98  92  79]\n [ 84  70  58  51  44  48  62  80 103 102  83  69  68  85  87  79  57  52\n   50  41  38  42  54  62  68  63  56  47]\n [ 76  69  63  62  69  74  70  69  85  95  98  99 107 125  97  68  49  55\n   69  72  66  53  51  48  48  45  41  35]\n [ 69  63  44  50  64  91 107  92  97 105 104  99  91  84  66  52  46  49\n   52  67  73  72  61  53  46  44  47  49]\n [ 61  66  54  46  49  59  66  79  95 107 106  83  63  59  56  52  48  41\n   42  57  63  66  60  59  71  73  76  80]\n [ 71  89  94  88  82  71  66  83  93  95  92  82  77  86  81  71  57  53\n   60  72  74  78  77  80  93  90  90  88]\n [ 78  61  60  68  75  82  80  91  96 104 103 109 112 110  95  78  68  73\n   76  73  69  68  74  92  98  91  88  84]\n [ 67  66  63  63  67  71  80 100 103 102  93 102 102  95  90  80  71  62\n   54  54  61  63  64  76  77  77  75  71]\n [ 74  70  72  72  79  78  84 102 112 112 114 121 111  96  86  69  60  55\n   62  58  60  62  63  67  74  80  82  76]\n [ 85  81  73  73  82  82  77  82  95  97  93  85  78  78  78  63  54  54\n   54  50  50  51  50  59  71  77  79  72]]",
         "1"
        ],
        [
         "3",
         "[[167 163 162 151 145 133 139 149 150 149 152 159 159 158 152 142 136 139\n  138 134 137 126 129 130 139 145 149 158]\n [122 129 145 137 120 105 103 107 114 116 117 124 123 130 125 120 112 104\n   98  95 100 102 117  97 104 126 135 145]\n [126 128 135 123 128 113 101 108 107 112 110 122 114 115 119 113 108 114\n  124 121 132 140 136 123 129 132 135 133]\n [123 122 128 120 117 105 107 117 116 112 121 126 125 126 128 136 149 146\n  122 124 123 119 121 124 126 131 136 134]\n [131 131 130 137 141 124 124 136 131 130 124 118 133 156 161 161 171 148\n  121 121 127 127 137 135 133 139 141 137]\n [136 134 137 124 139 145 143 146 134 135 129 126 134 145 149 147 150 150\n  118 116 129 152 155 144 137 134 144 139]\n [132 137 129 108 125 141 136 144 139 137 148 163 150 154 159 170 171 138\n  114 117 135 168 158 139 147 145 146 141]\n [127 126 118 115 133 144 134 149 165 185 189 184 195 213 216 208 205 175\n  146 143 158 148 139 146 152 141 147 155]\n [142 146 138 148 169 184 172 193 203 194 173 156 161 201 219 210 185 156\n  155 169 175 153 144 152 155 159 171 192]\n [185 176 163 159 167 179 182 177 178 174 160 160 155 131 127 125 119 130\n  146 166 178 160 171 175 187 198 211 214]\n [157 153 139 136 136 145 151 149 149 158 149 151 142  88  75  77  82 111\n  131 143 155 152 176 190 204 221 223 208]\n [145 152 149 137 138 149 158 145 127 129 130 138 144 142 131 127 131 114\n  109 125 129 128 148 174 190 194 182 156]\n [146 146 145 135 140 141 137 126 109 106 109 116 130 156 173 166 141 105\n   92 101  99  94 108 136 156 161 153 143]\n [140 147 157 156 148 151 147 143 136 129 125 128 149 161 159 150 138 120\n  105  97  91  87 101 117 125 130 127 122]\n [140 139 144 154 156 145 137 139 135 130 124 120 135 151 153 141 129 118\n   98  87  84  78  88  97 107 109 103 105]\n [144 137 136 138 145 137 130 126 131 130 128 126 133 151 153 141 130 111\n   89  85  78  71  81  87  95 107 107 111]\n [119 123 123 133 136 129 124 119 121 124 132 140 158 175 177 164 155 135\n  107  91  76  66  76  93 103 100 100 104]\n [135 147 154 170 176 169 156 132 119 105 104 110 134 145 153 152 145 134\n  126 121 114 100  94  97  95  93  84  91]\n [108 112 118 128 136 138 127 112  95  86  84  89 104 114 117 119 112 102\n   97 101 102 103 108 113 119 116 102  96]\n [ 88  91 103 113 110 105  89  82  76  73  75  78  88  98  98  95  90  81\n   77  76  75  75  80  88 101 113 121 126]\n [ 75  78  83  88  89  83  73  67  62  64  67  70  78  87  88  81  78  69\n   63  60  56  56  63  68  71  77  86  98]\n [ 67  72  75  76  74  70  60  55  53  53  55  61  68  75  77  72  68  58\n   53  48  44  42  48  53  58  66  68  74]\n [ 56  58  63  64  62  58  50  49  46  44  48  53  62  65  65  64  60  52\n   47  43  39  38  39  42  45  50  52  59]\n [ 50  53  56  56  54  49  43  39  39  39  44  51  57  60  61  55  51  47\n   44  42  36  36  36  37  38  38  41  46]\n [ 43  46  49  48  45  42  39  35  33  36  40  46  50  54  57  51  47  45\n   43  40  35  33  31  32  31  34  37  39]\n [ 39  43  45  43  41  38  34  31  31  33  37  42  46  47  45  45  44  41\n   37  36  33  30  28  27  28  31  34  35]\n [ 36  36  38  37  37  32  28  26  26  25  30  35  36  38  38  40  38  36\n   31  31  29  26  25  25  26  27  31  31]\n [ 34  36  35  34  32  29  25  23  22  21  25  28  29  30  31  30  28  26\n   22  25  24  24  23  25  25  26  27  29]]",
         "1"
        ],
        [
         "4",
         "[[  1   6  41  79 159 180 175 175 175 181 190 194 193 190 190 188 187 185\n  183 180 182 187 191 150  18   1   1   1]\n [  1   1   9 110 187 186 183 183 185 191 196 198 198 201 199 195 197 194\n  194 194 190 191 192 180  69   1   1   1]\n [  1   1  31 168 201 200 200 181 160 142 132 134 136 147 163 183 203 207\n  207 210 203 200 195 192 140  15   1   1]\n [  1   3  88 184 191 186 153 114  95  88  90  97  93  98 107 120 145 161\n  164 177 196 210 208 186 172  64   1   1]\n [  1  23 130 165 172 148 102  87  85  85  92 101  89  93 102  99 105 107\n  108 116 132 155 180 178 175 129  14   1]\n [  3  67 131 145 134  99  93  94  98  99 111 114 100 100  98  94  96  94\n   86  90 109 113 133 171 184 162  53   1]\n [ 22 106 133 133  92  77  90 101 106 111 123 111 100  99  97 104 105 103\n   82  82 102  99 102 131 163 160  96  11]\n [ 60 108 120 101  73  88 101 106 113 120 124 115 114 114 109 116 122 123\n  100  88  97 102  95 101 116 124 101  36]\n [ 92  93  86  66  63  92 105 116 123 117 117 120 121 127 123 123 123 122\n  116 101  97  99  93  85  81  93  92  64]\n [ 80  83  65  54  73  83  99 103 115 115 111 108 109 119 124 121 123 119\n  102  90  88  94  88  78  69  81  92  76]\n [ 70  70  67  62  80  90  94 101 111 115 103 114 107 111 119 114 111 107\n   99  97  89  97  83  69  65  65  74  67]\n [ 61  60  54  58  65  73  83  96  99 104 106 113 116 118 113  97  89  94\n   95  94  90  90  81  71  62  63  70  67]\n [ 59  53  52  57  64  68  77  89  91  93 103 111 106 110 108  97  91  86\n   82  75  67  64  71  75  67  69  71  72]\n [ 61  59  58  66  71  76  82  84  82  86 100 105  96  92 101  96  89  77\n   74  67  62  68  72  68  63  61  63  59]\n [ 52  51  53  64  72  73  73  72  69  72  82  88  87  87  89  78  77  72\n   65  63  66  69  69  51  47  50  61  65]\n [ 73  81  57  57  60  58  55  60  57  58  64  66  65  68  76  76  75  77\n   83  81  78  62  53  50  46  49  75  75]\n [ 75 117  81  55  49  51  51  50  65  57  52  54  56  59  75  80  76  71\n   66  66  70  61  53  49  44  62 105  87]\n [ 67 107 120  66  48  44  45  47  52  50  49  60  67  69  78  77  72  58\n   57  64  66  58  49  49  50  82 122 114]\n [ 74  87 138 119  76  56  49  51  54  55  55  61  58  65  72  72  68  64\n   62  64  60  53  48  54  90 133 137 125]\n [118 108 113 141 146 111  70  60  53  52  52  60  64  64  67  60  52  49\n   48  54  59  61  84 125 156 147 131 121]\n [111 121 131 123 136 157 160 140  97  69  61  66  69  62  66  76  88  87\n   94 121 134 146 163 163 155 134 117  97]\n [136 139 132 119 110 114 132 145 135 118  84  62  65  66  89 121 147 156\n  166 161 148 143 136 124 110  96  91  87]\n [126 142 143 128 134 126 120 128 119 119 115  87  75  89 133 148 147 150\n  147 139 135 134 121  99  84  78  80  77]\n [ 86 119 121 109 118 117 119 123 133 137 129 133 140 152 154 135 126 120\n  115 122 126 120 118  96  80  76  84  98]\n [ 77  84  91  93 101 105 110 104 115 122 130 143 154 155 152 133 119 110\n  109 110 109 106  99  86  79  81  93 104]\n [ 77  87  91  95  96  96  97  92  99 106 110 107 112 115 117 111 102  98\n   94  90  87  85  85  86  80  80  81  82]\n [ 69  84  91  88  81  80  88  79  75  78  78  86  95  93  94  92  97 100\n   94  93  80  74  78  84  73  64  69  82]\n [ 48  52  54  56  61  65  65  65  65  64  67  84  92  91  90  93 102  94\n   73  65  59  60  68  74  69  60  60  58]]",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[139, 139, 138, 139, 142, 149, 156, 159, 164,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[82, 85, 83, 78, 76, 76, 79, 79, 76, 80, 86, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[157, 155, 151, 145, 149, 146, 141, 134, 141,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[167, 163, 162, 151, 145, 133, 139, 149, 150,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[1, 6, 41, 79, 159, 180, 175, 175, 175, 181, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  [[139, 139, 138, 139, 142, 149, 156, 159, 164,...      1\n",
       "1  [[82, 85, 83, 78, 76, 76, 79, 79, 76, 80, 86, ...      1\n",
       "2  [[157, 155, 151, 145, 149, 146, 141, 134, 141,...      1\n",
       "3  [[167, 163, 162, 151, 145, 133, 139, 149, 150,...      1\n",
       "4  [[1, 6, 41, 79, 159, 180, 175, 175, 175, 181, ...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aab5995d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 546 entries, 0 to 545\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   image   546 non-null    object\n",
      " 1   label   546 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 8.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc8c03a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "442a6ab8-9f00-4164-bd14-bfcc8c4994cd",
       "rows": [
        [
         "1",
         "399"
        ],
        [
         "0",
         "147"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "label\n",
       "1    399\n",
       "0    147\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84886528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define a sample\n",
    "sample = train_df.iloc[0]\n",
    "\n",
    "img_np = sample[\"image\"] \n",
    "label  = sample[\"label\"]\n",
    "\n",
    "plt.imshow(img_np, cmap='gray')\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df76f965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape:\",img_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6f6c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save images and labels in a list\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for img, label in test_dataset:\n",
    "    images.append(np.array(img))\n",
    "    labels.append(int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44c27b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df of the extracted data\n",
    "test_df = pd.DataFrame({\n",
    "    \"image\": images,\n",
    "    \"label\": labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9025fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "736b9900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# device definition: gpu/ cpu\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40faf30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.stack(train_df['image'].values)\n",
    "y_train = np.array(train_df['label'].values)\n",
    "\n",
    "X_test = np.stack(test_df['image'].values)\n",
    "y_test = np.array(test_df['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97b00a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546, 28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a972c9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546, 28, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0a86f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA expects array of dim 2 as input --> flatten the 28x28 matrix to 784 features\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1) # X_train.shape[0] keeps number of samples, -1 flattens everything else in one long vector\n",
    "X_test_flat  = X_test.reshape(X_test.shape[0], -1)\n",
    "X_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f7f7a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "n_features = 8\n",
    "pca = PCA(n_components=n_features)\n",
    "X_train_pca = pca.fit_transform(X_train_flat)\n",
    "X_test_pca  = pca.transform(X_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dd37b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 8)\n",
      "(156, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pca.shape)  # (546, 8)\n",
    "print(X_test_pca.shape)   # (whatever test samples, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c630d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert X,y into torch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "y__train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e1008bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X_train_t = torch.tensor(X_train_pca, dtype=torch.float32).to(device)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "X_test_t  = torch.tensor(X_test_pca, dtype=torch.float32).to(device)\n",
    "y_test_t  = torch.tensor(y_test, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e4c6a1",
   "metadata": {},
   "source": [
    "# QCNN Approach 1 - Image classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6320054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parity_probs(model, fparams, aparams, X, theta):\n",
    "    \"\"\"Compute [p0, p1] for every input x in X.\"\"\"\n",
    "    out = []\n",
    "    for x in X:\n",
    "        bind = {p: float(v) for p, v in zip(fparams, x)}\n",
    "        bind.update({p: float(v) for p, v in zip(aparams, theta)})\n",
    "\n",
    "        sv = Statevector.from_instruction(model.assign_parameters(bind))\n",
    "        dist = sv.probabilities_dict()\n",
    "\n",
    "        p1 = sum(p for bit, p in dist.items() if bit.count(\"1\") % 2 == 1)\n",
    "        out.append([1 - p1, p1])\n",
    "    return np.array(out)\n",
    "\n",
    "def xent(probs, y_onehot, eps=1e-12):\n",
    "    return float(-np.mean(np.sum(y_onehot * np.log(probs + eps), axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614c52ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "qubit_list = [1, 2, 5, 10]\n",
    "max_iterations = 60\n",
    "\n",
    "results = {\n",
    "    'n_qubits': [],\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'test_acc': [],\n",
    "    'test_auc': [],\n",
    "    'n_params': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00fd99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "capi_return is NULL\n",
      "Call-back cb_calcfc_in__cobyla__user__routines failed.\n",
      "Fatal Python error: F2PySwapThreadLocalCallbackPtr: PyLong_AsVoidPtr failed\n",
      "Python runtime state: initialized\n",
      "  File \"/var/folders/9j/mh4k6dbx5sldmm3_0tzdsch00000gn/T/ipykernel_14280/3114810135.py\", line 25, in <module>\n",
      "  File \"/Users/ramonwinkler/anaconda3/envs/minerva/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 687, in minimize\n",
      "    res = _minimize_powell(fun, x0, args, callback, bounds, **options)\n",
      "  File \"/Users/ramonwinkler/anaconda3/envs/minerva/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 3335, in _minimize_powell\n",
      "    fval = squeeze(func(x))\n",
      "  File \"/Users/ramonwinkler/anaconda3/envs/minerva/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 569, in function_wrapper\n",
      "    fx = function(np.copy(x), *(wrapper_args + args))\n",
      "  File \"/var/folders/9j/mh4k6dbx5sldmm3_0tzdsch00000gn/T/ipykernel_14280/3114810135.py\", line 20, in objective\n",
      "NameError: name 'X_train_theta' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ramonwinkler/anaconda3/envs/minerva/lib/python3.8/site-packages/scipy/optimize/_cobyla_py.py\", line 258, in calcfc\n",
      "    f = fun(np.copy(x), *args)\n",
      "  File \"/var/folders/9j/mh4k6dbx5sldmm3_0tzdsch00000gn/T/ipykernel_14280/3114810135.py\", line 20, in objective\n",
      "NameError: name 'X_train_theta' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TRAINING 1 QUBITS =====\n",
      "Powell failed → using COBYLA...\n"
     ]
    }
   ],
   "source": [
    "for n_qubits in qubit_list:\n",
    "    print(f\"\\n===== TRAINING {n_qubits} QUBITS =====\")\n",
    "\n",
    "    # Build circuit\n",
    "    feature_map = ZFeatureMap(n_qubits, reps=1)\n",
    "    ansatz      = RealAmplitudes(n_qubits, reps=1)\n",
    "\n",
    "    model = QuantumCircuit(n_qubits)\n",
    "    model.compose(feature_map, inplace=True)\n",
    "    model.compose(ansatz, inplace=True)\n",
    "\n",
    "    fparams = list(feature_map.parameters)\n",
    "    aparams = list(ansatz.parameters)\n",
    "    n_params = len(aparams)\n",
    "\n",
    "    theta0 = np.zeros(n_params)\n",
    "\n",
    "    # Objective for optimizer\n",
    "    def objective(theta):\n",
    "        probs = parity_probs(model, fparams, aparams, X_train_theta, theta)\n",
    "        return xent(probs, y_train_oh)\n",
    "\n",
    "    # Train parameters\n",
    "    try:\n",
    "        res = minimize(objective, theta0, method=\"Powell\",\n",
    "                       options={\"maxiter\": max_iterations})\n",
    "        theta_opt = res.x\n",
    "        best_loss = res.fun\n",
    "        print(\"Optimized with Powell.\")\n",
    "    except Exception:\n",
    "        print(\"Powell failed → using COBYLA...\")\n",
    "        opt = COBYLA(maxiter=max_iterations, tol=1e-3)\n",
    "        res = opt.minimize(objective, x0=theta0)\n",
    "        theta_opt = res.x\n",
    "        best_loss = res.fun\n",
    "\n",
    "    # --------------------------\n",
    "    # Evaluate on full train set\n",
    "    # --------------------------\n",
    "    train_probs = parity_probs(model, fparams, aparams, X_train_theta, theta_opt)\n",
    "    train_pred  = np.argmax(train_probs, axis=1)\n",
    "    train_label = np.argmax(y_train_oh, axis=1)\n",
    "\n",
    "    train_acc = accuracy_score(train_label, train_pred)\n",
    "\n",
    "    # ------------------------\n",
    "    # Evaluate on full test set\n",
    "    # ------------------------\n",
    "    test_probs = parity_probs(model, fparams, aparams, X_test_theta, theta_opt)\n",
    "    test_pred  = np.argmax(test_probs, axis=1)\n",
    "\n",
    "    test_acc = accuracy_score(y_test, test_pred)\n",
    "    test_auc = roc_auc_score(y_test, test_probs[:,1])\n",
    "\n",
    "    # Store results\n",
    "    results['n_qubits'].append(n_qubits)\n",
    "    results['train_loss'].append(best_loss)\n",
    "    results['train_acc'].append(train_acc)\n",
    "    results['test_acc'].append(test_acc)\n",
    "    results['test_auc'].append(test_auc)\n",
    "    results['n_params'].append(n_params)\n",
    "\n",
    "    print(f\"Train loss: {best_loss:.4f}\")\n",
    "    print(f\"Train acc:  {train_acc:.3f}\")\n",
    "    print(f\"Test  acc:  {test_acc:.3f}\")\n",
    "    print(f\"Test  AUC:  {test_auc:.3f}\")\n",
    "    print(f\"Params:     {n_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc462c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Quantum Image Classifier (Clean Script)\n",
    "# Loops over qubits: [1, 2, 5, 10]\n",
    "# Uses all train and test data\n",
    "# Checks class imbalance\n",
    "# Evaluates train/test accuracy and AUC\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit.library import ZFeatureMap, RealAmplitudes\n",
    "from qiskit.quantum_info import Statevector\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# ============================================================\n",
    "# 0. SHOW CLASS IMBALANCE\n",
    "# ============================================================\n",
    "\n",
    "def show_class_imbalance(y, name):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"\\n=== Class Imbalance in {name} ===\")\n",
    "    for cls, cnt in zip(unique, counts):\n",
    "        print(f\"Class {cls}: {cnt} samples\")\n",
    "    print(f\"Ratio (minority/majority): {min(counts)}/{max(counts)}\")\n",
    "\n",
    "show_class_imbalance(y_train, \"Train Set\")\n",
    "show_class_imbalance(y_test, \"Test Set\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. PCA → Angle Encoding\n",
    "# ============================================================\n",
    "\n",
    "# angle scaling to [0, π]\n",
    "mins = X_train_pca.min(axis=0)\n",
    "maxs = X_train_pca.max(axis=0)\n",
    "denom = np.where((maxs - mins) == 0, 1, (maxs - mins))\n",
    "\n",
    "def to_angles(X):\n",
    "    \"\"\"Normalize PCA features to [0, π] for rotation angles.\"\"\"\n",
    "    return (X - mins) / denom * np.pi\n",
    "\n",
    "X_train_theta = to_angles(X_train_pca)\n",
    "X_test_theta  = to_angles(X_test_pca)\n",
    "\n",
    "# One-hot labels for cross entropy\n",
    "y_train_oh = np.eye(2)[y_train]\n",
    "y_test_oh  = np.eye(2)[y_test]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. HELPERS: Build circuit + compute probabilities\n",
    "# ============================================================\n",
    "\n",
    "def build_model_circuit(n_qubits):\n",
    "    \"\"\"Create feature map + ansatz + full model.\"\"\"\n",
    "    fm = ZFeatureMap(n_qubits, reps=1)\n",
    "    an = RealAmplitudes(n_qubits, reps=1)\n",
    "\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "    qc.compose(fm, inplace=True)\n",
    "    qc.compose(an, inplace=True)\n",
    "\n",
    "    return qc, list(fm.parameters), list(an.parameters)\n",
    "\n",
    "\n",
    "def build_bound_circuit(model, fparams, aparams, x, theta):\n",
    "    \"\"\"Assign PCA features (x) + trainable parameters (theta).\"\"\"\n",
    "    bind = {p: float(v) for p, v in zip(fparams, x)}\n",
    "    bind.update({p: float(v) for p, v in zip(aparams, theta)})\n",
    "    return model.assign_parameters(bind)\n",
    "\n",
    "\n",
    "def parity_probabilities(X, model, fparams, aparams, theta):\n",
    "    \"\"\"\n",
    "    Return Nx2 array of class probabilities:\n",
    "    p0 = even parity\n",
    "    p1 = odd parity\n",
    "    \"\"\"\n",
    "    probs = []\n",
    "\n",
    "    for x in X:\n",
    "        sv = Statevector.from_instruction(\n",
    "            build_bound_circuit(model, fparams, aparams, x, theta)\n",
    "        )\n",
    "        dist = sv.probabilities_dict()\n",
    "\n",
    "        p1 = sum(p for bit, p in dist.items() if bit.count(\"1\") % 2 == 1)\n",
    "        probs.append([1 - p1, p1])\n",
    "\n",
    "    return np.array(probs)\n",
    "\n",
    "\n",
    "def cross_entropy(probs, y_onehot, eps=1e-12):\n",
    "    \"\"\"Binary cross entropy.\"\"\"\n",
    "    return -np.mean(np.sum(y_onehot * np.log(probs + eps), axis=1))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. MAIN LOOP: Train & Evaluate for Different Qubit Counts\n",
    "# ============================================================\n",
    "\n",
    "qubit_list = [1, 2, 5, 10]\n",
    "max_iterations = 60\n",
    "\n",
    "results = {\n",
    "    \"n_qubits\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"test_acc\": [],\n",
    "    \"test_auc\": [],\n",
    "    \"n_params\": [],\n",
    "    \"train_loss\": []\n",
    "}\n",
    "\n",
    "print(\"\\n==================== START TRAINING ====================\")\n",
    "\n",
    "for n_qubits in qubit_list:\n",
    "    print(f\"\\n\\n=== Training with {n_qubits} qubits ===\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Build model\n",
    "    # --------------------------------------------------------\n",
    "    model, fparams, aparams = build_model_circuit(n_qubits)\n",
    "    n_params = len(aparams)\n",
    "\n",
    "    print(f\"Trainable parameters = {n_params}\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # TRAINING (all training data)\n",
    "    # --------------------------------------------------------\n",
    "\n",
    "    def objective(theta):\n",
    "        probs = parity_probabilities(X_train_theta, model, fparams, aparams, theta)\n",
    "        return cross_entropy(probs, y_train_oh)\n",
    "\n",
    "    theta0 = np.zeros(n_params, dtype=float)\n",
    "\n",
    "    try:\n",
    "        res = minimize(\n",
    "            objective,\n",
    "            theta0,\n",
    "            method=\"Powell\",\n",
    "            options={\"maxiter\": max_iterations, \"disp\": False},\n",
    "        )\n",
    "        theta_opt = res.x\n",
    "        best_loss = res.fun\n",
    "        print(\"Optimizer: SciPy Powell\")\n",
    "    except Exception:\n",
    "        opt = COBYLA(maxiter=max_iterations)\n",
    "        res = opt.minimize(objective, x0=theta0)\n",
    "        theta_opt = res.x\n",
    "        best_loss = objective(theta_opt)\n",
    "        print(\"Optimizer: COBYLA (fallback)\")\n",
    "\n",
    "    print(f\"Best train loss = {best_loss:.4f}\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # EVALUATE\n",
    "    # --------------------------------------------------------\n",
    "\n",
    "    # TRAIN SET\n",
    "    train_probs = parity_probabilities(X_train_theta, model, fparams, aparams, theta_opt)\n",
    "    train_pred  = np.argmax(train_probs, axis=1)\n",
    "    train_acc   = accuracy_score(y_train, train_pred)\n",
    "\n",
    "    # TEST SET\n",
    "    test_probs = parity_probabilities(X_test_theta, model, fparams, aparams, theta_opt)\n",
    "    test_pred  = np.argmax(test_probs, axis=1)\n",
    "    test_acc   = accuracy_score(y_test, test_pred)\n",
    "\n",
    "    # TEST AUC\n",
    "    test_auc = roc_auc_score(y_test, test_probs[:, 1])\n",
    "\n",
    "    print(f\"Train accuracy = {train_acc:.3f}\")\n",
    "    print(f\"Test accuracy  = {test_acc:.3f}\")\n",
    "    print(f\"Test AUC       = {test_auc:.3f}\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # SAVE RESULTS\n",
    "    # --------------------------------------------------------\n",
    "    results[\"n_qubits\"].append(n_qubits)\n",
    "    results[\"n_params\"].append(n_params)\n",
    "    results[\"train_loss\"].append(best_loss)\n",
    "    results[\"train_acc\"].append(train_acc)\n",
    "    results[\"test_acc\"].append(test_acc)\n",
    "    results[\"test_auc\"].append(test_auc)\n",
    "\n",
    "print(\"\\n==================== DONE ====================\")\n",
    "print(\"\\nResults:\", results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minerva",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
